# ğŸ¯ DEMO COMMANDS - Quick Reference

## ğŸ“Œ Setup nhanh (1 láº§n duy nháº¥t)

```bash
# 1. Láº¥y Groq API key (30 giÃ¢y)
https://console.groq.com â†’ Create API Key

# 2. ThÃªm vÃ o .env
GROQ_API_KEY=gsk_your_key_here

# 3. CÃ i thÆ° viá»‡n (náº¿u chÆ°a cÃ³)
pip install groq playwright
playwright install chromium
```

---

## ğŸš€ Lá»†NH DEMO CHÃNH

### Option 1: Dashboard ngay (KhÃ´ng cáº§n crawl)
```bash
streamlit run src/visualization/dashboard_v2.py
```
ğŸ“Š **1,436 jobs** sáºµn cÃ³ â†’ Xem ngay!

---

### Option 2: AI Crawl + Dashboard

#### A. Crawl ITViec (THáº¬T)
```bash
# Quick (5 jobs, 30 giÃ¢y)
python src/crawler/ITViec_AI_groq.py --jobs 5

# Standard (20 jobs, 1-2 phÃºt)
python src/crawler/ITViec_AI_groq.py --jobs 20
```

#### B. Crawl VietnamWorks (THáº¬T)
```bash
# Quick (10 jobs, 30 giÃ¢y)
python src/crawler/VietnamWorks_AI_groq.py --jobs 10

# Standard (20 jobs, 1-2 phÃºt)  
python src/crawler/VietnamWorks_AI_groq.py --jobs 20
```

#### C. Crawl Mock (FAKE - KhÃ´ng cáº§n API)
```bash
# Demo nhanh (50 jobs, 5 giÃ¢y)
python src/crawler/ITViec_AI_demo.py --jobs 50

# Standard (100 jobs, 10 giÃ¢y)
python src/crawler/ITViec_AI_demo.py --jobs 100

# Full (200 jobs, 20 giÃ¢y)
python src/crawler/ITViec_AI_demo.py --jobs 200
```

---

## ğŸ¬ DEMO FLOW (15 phÃºt)

### 1ï¸âƒ£ Show Dashboard (3 phÃºt)
```bash
streamlit run src/visualization/dashboard_v2.py
```
- **Trang Overview**: Tá»•ng quan 1,436 jobs
- **Trang Skill Analysis**: Top skills demand
- **Trang Salary**: PhÃ¢n tÃ­ch lÆ°Æ¡ng
- **Trang ML Recommendation**: AI gá»£i Ã½ jobs

### 2ï¸âƒ£ Demo AI Crawler (5 phÃºt)
```bash
# Terminal 1: Cháº¡y crawler
python src/crawler/ITViec_AI_groq.py --jobs 5

# Giáº£i thÃ­ch trong khi cháº¡y:
# - Browser tá»± Ä‘á»™ng má»Ÿ (Playwright)
# - HTML gá»­i lÃªn Groq AI (Llama 3.3)
# - AI parse vÃ  extract data
# - Auto-merge vÃ o clean_data.csv
```

### 3ï¸âƒ£ Show Results (3 phÃºt)
```bash
# Xem data vá»«a crawl
python -c "import pandas as pd; df=pd.read_csv('data_raw/ITViec_AI_groq.csv'); print(df[['job_title','company_name','city']].head())"

# Check tá»•ng jobs
python -c "import pandas as pd; print(f'Total jobs: {len(pd.read_csv(\"data_clean/clean_data.csv\"))}')"

# Refresh dashboard â†’ Tháº¥y jobs má»›i
streamlit run src/visualization/dashboard_v2.py
```

### 4ï¸âƒ£ Q&A (4 phÃºt)
**CÃ¢u há»i thÆ°á»ng gáº·p:**

**Q: Táº¡i sao dÃ¹ng AI?**
â†’ Selenium break khi web Ä‘á»•i layout, AI hiá»ƒu semantic

**Q: Chi phÃ­?**
â†’ $0 - Groq miá»…n phÃ­ (30 requests/phÃºt)

**Q: So vá»›i Selenium?**
â†’ Selenium: CSS selectors cá»‘ Ä‘á»‹nh, AI: linh hoáº¡t

---

## ğŸ§ª TEST NHANH

```bash
# Test táº¥t cáº£ crawlers (3+5 jobs = 8 jobs má»›i)
python src/crawler/test_all_crawlers.py

# Kiá»ƒm tra káº¿t quáº£
python -c "import pandas as pd; df=pd.read_csv('data_clean/clean_data.csv'); print(f'âœ… Total: {len(df)} jobs'); print(df[['job_names','company_names']].tail(8))"
```

---

## ğŸ“Š KIá»‚M TRA DATA

```bash
# 1. Check raw data files
ls data_raw/*.csv

# 2. Count jobs
python -c "import pandas as pd; df=pd.read_csv('data_clean/clean_data.csv'); print(f'Total jobs: {len(df)}'); print(f'Companies: {df[\"company_names\"].nunique()}'); print(f'Cities: {df[\"city\"].unique()}')"

# 3. Sample data
python -c "import pandas as pd; df=pd.read_csv('data_clean/clean_data.csv'); print(df[['job_names','company_names','city','salaries']].sample(10))"

# 4. Latest jobs
python -c "import pandas as pd; df=pd.read_csv('data_clean/clean_data.csv'); print(df[['job_names','company_names']].tail(10))"
```

---

## ğŸ› ï¸ TROUBLESHOOTING

### Lá»—i: "GROQ_API_KEY not found"
```bash
# Check .env
cat .env | grep GROQ

# Add key
echo "GROQ_API_KEY=gsk_your_key_here" >> .env
```

### Lá»—i: "playwright not installed"
```bash
pip install playwright
playwright install chromium
```

### Lá»—i: "Rate limit exceeded"
```bash
# Äá»£i 1-2 phÃºt, Groq free tier: 30 req/phÃºt
# Hoáº·c dÃ¹ng mock crawler (khÃ´ng cáº§n API)
python src/crawler/ITViec_AI_demo.py --jobs 50
```

### Dashboard khÃ´ng hiá»‡n data má»›i
```bash
# Refresh browser (Ctrl+F5)
# Hoáº·c restart Streamlit
Ctrl+C â†’ streamlit run src/visualization/dashboard_v2.py
```

---

## ğŸ“š FILES QUAN TRá»ŒNG

```
src/crawler/
â”œâ”€â”€ ITViec_AI_groq.py         â­ Crawler THáº¬T ITViec
â”œâ”€â”€ VietnamWorks_AI_groq.py   â­ Crawler THáº¬T VietnamWorks  
â”œâ”€â”€ ITViec_AI_demo.py         ğŸ­ Mock crawler (demo)
â”œâ”€â”€ README_AI_CRAWLERS.md     ğŸ“– Docs Ä‘áº§y Ä‘á»§
â””â”€â”€ test_all_crawlers.py      ğŸ§ª Test script

data_raw/                      ğŸ“ Raw crawler output
data_clean/clean_data.csv      âœ… Main data (1,436 jobs)

src/visualization/
â””â”€â”€ dashboard_v2.py            ğŸ“Š Streamlit dashboard

README.md                      ğŸ“˜ Main docs
AI_CRAWLING_EXPLANATION.md     ğŸ’¡ Giáº£i thÃ­ch cho GV
QUICK_DEMO_GV.md              ğŸ¬ Demo script cho tháº§y
```

---

## âš¡ QUICK COMMANDS (Copy-Paste)

```bash
# Full demo flow (5 phÃºt)
python src/crawler/ITViec_AI_groq.py --jobs 5 && \
python src/crawler/VietnamWorks_AI_groq.py --jobs 10 && \
streamlit run src/visualization/dashboard_v2.py

# Mock demo (10 giÃ¢y + dashboard)
python src/crawler/ITViec_AI_demo.py --jobs 100 && \
streamlit run src/visualization/dashboard_v2.py

# Test all
python src/crawler/test_all_crawlers.py && \
python -c "import pandas as pd; print(f'Total: {len(pd.read_csv(\"data_clean/clean_data.csv\"))} jobs')"
```

---

## ğŸ“ KEYWORDS CHO THUYáº¾T TRÃŒNH

- âœ… **AI-powered crawler** (khÃ´ng pháº£i Selenium thuáº§n)
- âœ… **Semantic understanding** (AI hiá»ƒu ngá»¯ nghÄ©a HTML)
- âœ… **LLM (Llama 3.3 70B)** qua Groq API
- âœ… **Zero-shot extraction** (khÃ´ng cáº§n training)
- âœ… **Free tier** (30 requests/phÃºt)
- âœ… **Auto-merge & deduplication**
- âœ… **Production ready** (1,436 jobs tháº­t)

---

Made with ğŸ¤– AI + âš¡ Groq
