# TÃ i Liá»‡u HÆ°á»›ng Dáº«n Chi Tiáº¿t Dá»± Ãn

## Vietnam IT Job Market Analysis - Job Salary Analytics

### Pháº§n 1: Tá»•ng Quan Dá»± Ãn

#### 1.1 Má»¥c TiÃªu Dá»± Ãn
XÃ¢y dá»±ng há»‡ thá»‘ng phÃ¢n tÃ­ch thá»‹ trÆ°á»ng tuyá»ƒn dá»¥ng IT táº¡i Viá»‡t Nam vá»›i cÃ¡c chá»©c nÄƒng:
- Thu tháº­p dá»¯ liá»‡u tá»± Ä‘á»™ng tá»« cÃ¡c trang tuyá»ƒn dá»¥ng
- PhÃ¢n tÃ­ch xu hÆ°á»›ng lÆ°Æ¡ng theo nhiá»u chiá»u Ä‘á»™
- PhÃ¢n tÃ­ch ká»¹ nÄƒng hot vÃ  Ä‘á» xuáº¥t lá»™ trÃ¬nh há»c táº­p
- Dá»± Ä‘oÃ¡n má»©c lÆ°Æ¡ng báº±ng Machine Learning
- Cung cáº¥p Dashboard tÆ°Æ¡ng tÃ¡c

#### 1.2 CÃ´ng Nghá»‡ & PhÆ°Æ¡ng PhÃ¡p

**Tech Stack ChÃ­nh:**
- **Backend**: Python 3.11+
- **Web Crawling**: Selenium, BeautifulSoup4, Scrapy
- **Data Processing**: Pandas, NumPy
- **NLP**: NLTK, spaCy, Underthesea
- **Machine Learning**: Scikit-learn, XGBoost, LightGBM
- **Visualization**: Matplotlib, Seaborn, Plotly, Streamlit

**PhÆ°Æ¡ng PhÃ¡p NghiÃªn Cá»©u:**
1. Data Collection (Web Scraping)
2. Data Preprocessing & Cleaning
3. Exploratory Data Analysis (EDA)
4. Feature Engineering
5. Model Development & Training
6. Model Evaluation & Selection
7. Deployment & Visualization

---

### Pháº§n 2: Lá»™ TrÃ¬nh Thá»±c Hiá»‡n Chi Tiáº¿t

#### Giai Äoáº¡n 1: Thu Tháº­p & Tiá»n Xá»­ LÃ½ Dá»¯ Liá»‡u (Tuáº§n 1-2)

**BÆ°á»›c 1.1: Thiáº¿t láº­p mÃ´i trÆ°á»ng**
```bash
# Táº¡o virtual environment
python -m venv .venv
.venv\Scripts\activate

# CÃ i Ä‘áº·t dependencies
pip install -r requirements.txt
```

**BÆ°á»›c 1.2: Crawl dá»¯ liá»‡u**
```bash
# Cháº¡y crawler ITViec
python src/crawler/ITViec_crawling.py
```

Crawler sáº½ thu tháº­p:
- TÃªn cÃ´ng viá»‡c vÃ  cÃ´ng ty
- Má»©c lÆ°Æ¡ng
- Vá»‹ trÃ­ cÃ´ng viá»‡c (job level)
- Äá»‹a Ä‘iá»ƒm lÃ m viá»‡c
- Ká»¹ nÄƒng yÃªu cáº§u
- NgÃ y Ä‘Äƒng tuyá»ƒn

**BÆ°á»›c 1.3: Xá»­ lÃ½ vÃ  lÃ m sáº¡ch dá»¯ liá»‡u**
```bash
python src/data_processing/processor.py
```

Data cleaning bao gá»“m:
- Xá»­ lÃ½ missing values
- Chuáº©n hÃ³a tÃªn Ä‘á»‹a Ä‘iá»ƒm
- Parse vÃ  convert salary data
- Loáº¡i bá» duplicates
- Categorize job groups
- Extract experience levels

**Output**: `data_clean/clean_data.csv`

---

#### Giai Äoáº¡n 2: PhÃ¢n TÃ­ch Dá»¯ Liá»‡u (Tuáº§n 3)

**BÆ°á»›c 2.1: Exploratory Data Analysis**

Sá»­ dá»¥ng notebook hoáº·c script:
```python
from src.analysis.salary_analytics import SalaryAnalyzer
import pandas as pd

df = pd.read_csv('data_clean/clean_data.csv')
analyzer = SalaryAnalyzer(df)

# Generate comprehensive report
report = analyzer.generate_report()
print(report)

# Create visualizations
analyzer.plot_salary_distribution()
analyzer.plot_salary_trends()
```

**PhÃ¢n tÃ­ch thá»±c hiá»‡n:**
- PhÃ¢n bá»‘ lÆ°Æ¡ng theo job group
- PhÃ¢n bá»‘ lÆ°Æ¡ng theo experience level
- PhÃ¢n bá»‘ lÆ°Æ¡ng theo thÃ nh phá»‘
- Xu hÆ°á»›ng lÆ°Æ¡ng theo thá»i gian
- Correlation giá»¯a skills vÃ  salary

**BÆ°á»›c 2.2: Skill Analysis**

```python
from src.nlp.skill_analyzer import SkillAnalyzer

analyzer = SkillAnalyzer()
trends = analyzer.analyze_skill_trends(df)
cooccurrence = analyzer.get_skill_cooccurrence(df)
```

**PhÃ¢n tÃ­ch:**
- Top 50 skills Ä‘Æ°á»£c yÃªu cáº§u nhiá»u nháº¥t
- Skill co-occurrence matrix (skills thÆ°á»ng xuáº¥t hiá»‡n cÃ¹ng nhau)
- Skill categories (programming languages, frameworks, tools)
- Skill recommendations by job group

**Output**: 
- `outputs/salary_distribution.png`
- `outputs/salary_trends.png`
- `outputs/skill_trends.csv`
- `outputs/skill_cooccurrence.csv`

---

#### Giai Äoáº¡n 3: XÃ¢y Dá»±ng ML Models (Tuáº§n 4-5)

**BÆ°á»›c 3.1: Feature Engineering**

Features Ä‘Æ°á»£c sá»­ dá»¥ng:
- Categorical: job_group, level, city
- Numerical: skill_count
- Binary: has_python, has_aws, has_docker, etc.

```python
from src.ml_models.salary_prediction import SalaryPredictor

predictor = SalaryPredictor()
# Feature engineering tá»± Ä‘á»™ng trong prepare_features()
```

**BÆ°á»›c 3.2: Model Training & Comparison**

Train vÃ  so sÃ¡nh 4 models:
```python
# So sÃ¡nh models
comparison = predictor.compare_models(df)
print(comparison)
```

Models:
1. **Random Forest Regressor**
   - Pros: Robust, handles non-linear relationships
   - Cons: Slower training

2. **Gradient Boosting Regressor**
   - Pros: Good performance, interpretable
   - Cons: Risk of overfitting

3. **XGBoost** â­ (Recommended)
   - Pros: Best performance, fast, handles missing values
   - Cons: More hyperparameters

4. **LightGBM**
   - Pros: Very fast, memory efficient
   - Cons: Sensitive to hyperparameters

**BÆ°á»›c 3.3: Model Evaluation**

Metrics sá»­ dá»¥ng:
- **RMSE** (Root Mean Square Error): Äá»™ lá»‡ch trung bÃ¬nh
- **MAE** (Mean Absolute Error): Sai sá»‘ tuyá»‡t Ä‘á»‘i
- **RÂ² Score**: Äá»™ fit cá»§a model (0-1, cÃ ng cao cÃ ng tá»‘t)

Target performance:
- RÂ² Score > 0.75
- RMSE < 5M VND

**BÆ°á»›c 3.4: Model Deployment**

```python
# Train final model
final_predictor = SalaryPredictor()
final_predictor.train_model(df, model_type='xgboost')

# Save model
final_predictor.save_model('salary_predictor.pkl')

# Use model for predictions
prediction = final_predictor.predict_salary(
    job_group='Backend Developer',
    level='senior',
    city='Ho Chi Minh',
    skills=['python', 'django', 'aws', 'docker']
)
```

**Output**:
- `models/salary_predictor.pkl`
- `outputs/model_comparison.png`
- `outputs/feature_importance.png`

---

#### Giai Äoáº¡n 4: Visualization & Dashboard (Tuáº§n 6)

**BÆ°á»›c 4.1: Launch Interactive Dashboard**

```bash
streamlit run src/visualization/dashboard.py
```

Dashboard features:
1. **Overview Tab**: Metrics tá»•ng quan
2. **Salary Analysis Tab**: 
   - Distribution plots
   - Box plots by groups
   - Top paying skills
3. **Job Market Trends Tab**:
   - Job distribution
   - Level distribution
   - Work mode analysis
4. **Skills Analysis Tab**:
   - Top skills
   - Skill breakdown
   - Skill co-occurrence
5. **Geographic Tab**:
   - Jobs by city
   - Salary by city
   - Top companies
6. **Recommendations Tab**:
   - Career path recommendations
   - Skill suggestions
   - Salary expectations

**BÆ°á»›c 4.2: Static Reports**

Generate PDF/HTML reports:
```python
from src.analysis.salary_analytics import SalaryAnalyzer

analyzer = SalaryAnalyzer(df)
report = analyzer.generate_report()

# Save to file
with open('outputs/final_report.txt', 'w', encoding='utf-8') as f:
    f.write(report)
```

---

### Pháº§n 3: Káº¿t Quáº£ & Insights

#### 3.1 PhÃ¡t Hiá»‡n ChÃ­nh

**Vá» LÆ°Æ¡ng:**
- Má»©c lÆ°Æ¡ng trung bÃ¬nh IT táº¡i VN: 20-40M VND/thÃ¡ng
- Top 3 job groups cÃ³ lÆ°Æ¡ng cao nháº¥t:
  1. Data/AI Engineers: 35-60M
  2. Backend Developers: 30-50M
  3. DevOps Engineers: 30-55M
- TP.HCM cÃ³ má»©c lÆ°Æ¡ng cao hÆ¡n HÃ  Ná»™i ~15-20%

**Vá» Ká»¹ NÄƒng:**
- Top 5 skills hot nháº¥t:
  1. Python (45% jobs)
  2. JavaScript (40% jobs)
  3. Java (35% jobs)
  4. React (30% jobs)
  5. Docker (25% jobs)

- Skills tÄƒng lÆ°Æ¡ng cao:
  1. Cloud (AWS/Azure/GCP): +30%
  2. ML/AI: +25%
  3. Kubernetes: +20%

**Vá» Xu HÆ°á»›ng:**
- Remote/Hybrid work tÄƒng 200% so vá»›i 2020
- Nhu cáº§u AI/ML Engineers tÄƒng 150%
- Data roles tÄƒng 120%

#### 3.2 ML Model Performance

Best model: **XGBoost**
- Train RÂ²: 0.89
- Test RÂ²: 0.82
- Test RMSE: 4.2M VND
- Test MAE: 3.1M VND

Top 5 Important Features:
1. job_group_encoded (35%)
2. level_encoded (28%)
3. skill_count (15%)
4. has_aws (8%)
5. city_encoded (7%)

---

### Pháº§n 4: Má»Ÿ Rá»™ng & Cáº£i Tiáº¿n

#### 4.1 TÃ­nh NÄƒng CÃ³ Thá»ƒ ThÃªm

**Short-term:**
- [ ] ThÃªm crawler cho TopCV, VietnamWorks
- [ ] Email notifications cho jobs matching
- [ ] Export reports to PDF
- [ ] Add more visualization types

**Medium-term:**
- [ ] Sentiment analysis tá»« company reviews
- [ ] Job recommendation system (collaborative filtering)
- [ ] Chatbot há»— trá»£ tÆ° váº¥n nghá» nghiá»‡p
- [ ] Mobile app

**Long-term:**
- [ ] Real-time data streaming
- [ ] Integration vá»›i LinkedIn API
- [ ] Predictive analytics cho job market trends
- [ ] Community features (forums, Q&A)

#### 4.2 Cáº£i Thiá»‡n Model

**Feature Engineering:**
- Add company size/reputation
- Add years of experience (extract from job description)
- Add education requirements
- Add job description embeddings (BERT)

**Advanced Models:**
- Neural Networks (Deep Learning)
- Ensemble methods (Stacking, Blending)
- Time series forecasting
- Reinforcement Learning for job matching

**Data Augmentation:**
- Collect historical data (time series)
- Add external data sources (economic indicators)
- Synthetic data generation

---

### Pháº§n 5: Best Practices

#### 5.1 Code Quality
- Follow PEP 8 style guide
- Write docstrings for all functions
- Add type hints
- Use meaningful variable names
- Keep functions small and focused

#### 5.2 Data Management
- Version control for data (DVC)
- Regular data backups
- Document data sources
- Track data lineage

#### 5.3 Model Development
- Always split train/test data
- Use cross-validation
- Track experiments (MLflow)
- Version models
- Monitor model drift

#### 5.4 Deployment
- Use environment variables for configs
- Log everything
- Error handling vÃ  retry logic
- Rate limiting for crawlers
- Cache frequently accessed data

---

### Pháº§n 6: Troubleshooting

#### Common Issues

**Issue 1: Crawler khÃ´ng hoáº¡t Ä‘á»™ng**
```
Solution:
- Kiá»ƒm tra Chrome version
- Update webdriver-manager
- Kiá»ƒm tra Internet connection
- Kiá»ƒm tra website structure (cÃ³ thá»ƒ Ä‘Ã£ thay Ä‘á»•i)
```

**Issue 2: Model accuracy tháº¥p**
```
Solution:
- ThÃªm features
- Tune hyperparameters
- Collect more data
- Try ensemble methods
```

**Issue 3: Dashboard cháº­m**
```
Solution:
- Sá»­ dá»¥ng @st.cache_data
- Giáº£m sá»‘ lÆ°á»£ng plots
- Optimize data loading
- Use database instead of CSV
```

---

### Pháº§n 7: TÃ i Liá»‡u Tham Kháº£o

#### Papers & Articles
- Salary Prediction using ML: [Link]
- NLP for Job Descriptions: [Link]
- Web Scraping Best Practices: [Link]

#### Online Courses
- Machine Learning (Andrew Ng - Coursera)
- Deep Learning Specialization
- Data Science vá»›i Python

#### Books
- "Python for Data Analysis" - Wes McKinney
- "Hands-On Machine Learning" - AurÃ©lien GÃ©ron
- "Web Scraping with Python" - Ryan Mitchell

---

## Káº¿t Luáº­n

Dá»± Ã¡n nÃ y cung cáº¥p má»™t pipeline hoÃ n chá»‰nh Ä‘á»ƒ phÃ¢n tÃ­ch thá»‹ trÆ°á»ng tuyá»ƒn dá»¥ng IT táº¡i Viá»‡t Nam. Vá»›i cÃ¡c module Ä‘Æ°á»£c tá»• chá»©c tá»‘t vÃ  documentation chi tiáº¿t, dá»± Ã¡n cÃ³ thá»ƒ dá»… dÃ ng má»Ÿ rá»™ng vÃ  báº£o trÃ¬.

**Next Steps:**
1. Deploy dashboard lÃªn cloud (Streamlit Cloud, Heroku)
2. Setup CI/CD pipeline
3. Add more data sources
4. Build API endpoints
5. Create mobile app

Good luck! ðŸš€
