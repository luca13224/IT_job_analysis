"""
Auto Process AI Data - Merge with existing data
Tá»± Ä‘á»™ng gá»™p data AI vÃ o data hiá»‡n cÃ³
"""
import pandas as pd
import re
from pathlib import Path

def extract_salary_numeric(salary_str):
    """Extract numeric salary"""
    if pd.isna(salary_str) or salary_str == 'Negotiable':
        return None
    
    numbers = re.findall(r'(\d+)', str(salary_str))
    if numbers:
        nums = [int(n) for n in numbers]
        avg = sum(nums) / len(nums)
        return avg * 1_000_000
    return None

def classify_job_group(job_title):
    """Classify job group"""
    title_lower = str(job_title).lower()
    
    if 'backend' in title_lower:
        return 'Backend Developer'
    elif 'frontend' in title_lower:
        return 'Frontend Developer'
    elif 'fullstack' in title_lower:
        return 'Fullstack Developer'
    elif 'mobile' in title_lower or 'ios' in title_lower or 'android' in title_lower:
        return 'Mobile Developer'
    elif 'data' in title_lower or 'ai' in title_lower:
        return 'Data / AI'
    elif 'devops' in title_lower:
        return 'DevOps / Cloud'
    else:
        return 'Backend Developer'  # Default

# Paths
project_root = Path(__file__).parent
ai_file = project_root / "data_raw" / "ITViec_AI_demo.csv"
existing_file = project_root / "data_clean" / "clean_data.csv"
output_file = project_root / "data_clean" / "clean_data.csv"  # Overwrite existing

print("="*70)
print("ğŸ¤– Tá»° Äá»˜NG Gá»˜P DATA AI VÃ€O DATA HIá»†N CÃ“")
print("="*70)

# Check if AI data exists
if not ai_file.exists():
    print(f"\nâŒ KhÃ´ng tÃ¬m tháº¥y file: {ai_file}")
    print("Vui lÃ²ng cháº¡y: python src/crawler/ITViec_AI_demo.py")
    exit(1)

# Load AI data
print(f"\nğŸ“¥ Äá»c data AI: {ai_file}")
df_ai = pd.read_csv(ai_file)
print(f"  âœ“ {len(df_ai)} jobs tá»« AI crawler")

# Process AI data to standard format
df_ai_processed = pd.DataFrame()
df_ai_processed['job_names'] = df_ai['job_title']
df_ai_processed['company_names'] = df_ai['company_name']
df_ai_processed['salaries'] = df_ai['salary']
df_ai_processed['position_names'] = df_ai['job_title']
df_ai_processed['kind_jobs'] = 'At office'
df_ai_processed['array_skills'] = df_ai['skills']
df_ai_processed['locate_names'] = df_ai['city']
df_ai_processed['exp_skills'] = df_ai['description']
df_ai_processed['domain_arr'] = '[]'
df_ai_processed['post_dates_formatted'] = df_ai['crawled_at']
df_ai_processed['salary_numeric'] = df_ai['salary'].apply(extract_salary_numeric)
df_ai_processed['job_group'] = df_ai['job_title'].apply(classify_job_group)
df_ai_processed['level'] = df_ai['level']
df_ai_processed['city'] = df_ai['city']

# Load existing data
print(f"\nğŸ“¥ Äá»c data hiá»‡n cÃ³: {existing_file}")
df_existing = pd.read_csv(existing_file)
print(f"  âœ“ {len(df_existing)} jobs hiá»‡n cÃ³")

# Merge
print(f"\nğŸ”„ Gá»™p data...")
df_merged = pd.concat([df_existing, df_ai_processed], ignore_index=True)

# Remove duplicates
before_dedup = len(df_merged)
df_merged = df_merged.drop_duplicates(subset=['job_names', 'company_names'], keep='first')
after_dedup = len(df_merged)
print(f"  âœ“ ÄÃ£ loáº¡i {before_dedup - after_dedup} jobs trÃ¹ng láº·p")

# Save
df_merged.to_csv(output_file, index=False, encoding='utf-8-sig')

print(f"\nâœ… HOÃ€N THÃ€NH!")
print(f"  â€¢ Tá»•ng jobs: {len(df_merged)}")
print(f"  â€¢ File output: {output_file}")

print("\nğŸ“Š Thá»‘ng kÃª:")
print(f"  â€¢ Job groups: {df_merged['job_group'].value_counts().to_dict()}")
print(f"  â€¢ Cities: {df_merged['city'].value_counts().to_dict()}")

print("\nğŸ¯ Dashboard sáº½ tá»± Ä‘á»™ng dÃ¹ng data má»›i nÃ y!")
print("   Refresh trang dashboard Ä‘á»ƒ tháº¥y data AI")
