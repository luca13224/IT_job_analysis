# ü§ñ AI Crawlers v·ªõi Groq API

## üìã T·ªïng quan

AI crawlers s·ª≠ d·ª•ng **Groq API** (mi·ªÖn ph√≠) + **Llama 3.3 70B** ƒë·ªÉ t·ª± ƒë·ªông parse HTML v√† extract job data.

### ‚ú® ∆Øu ƒëi·ªÉm
- ‚úÖ **MI·ªÑN PH√ç** - Groq free tier: 30 requests/ph√∫t
- ‚ö° **NHANH** - Nhanh h∆°n GPT-4, ch·ªâ 1-2 ph√∫t
- ü™∂ **NH·∫∏** - Kh√¥ng c·∫ßn download model (vs Ollama 5GB)
- üß† **AI TH·∫¨T** - LLM hi·ªÉu semantic, kh√¥ng c·∫ßn CSS selectors
- üîÑ **AUTO-MERGE** - T·ª± ƒë·ªông merge v√†o clean_data.csv

### üìä So s√°nh gi·∫£i ph√°p

| Gi·∫£i ph√°p | Chi ph√≠ | T·ªëc ƒë·ªô | Download | AI | Kh√≥ d√πng |
|-----------|---------|--------|----------|-----|----------|
| **Groq** ‚≠ê | $0 | ‚ö°‚ö°‚ö° | 0 GB | ‚úÖ | ‚≠ê D·ªÖ |
| Ollama | $0 | üêå | 5 GB | ‚úÖ | ‚≠ê‚≠ê Kh√≥ |
| GPT-4 | $$$ | ‚ö°‚ö° | 0 GB | ‚úÖ | ‚≠ê D·ªÖ |
| Selenium | $0 | ‚ö° | 0 GB | ‚ùå | ‚≠ê‚≠ê‚≠ê Kh√≥ |

---

## üöÄ Setup (2 ph√∫t)

### 1. L·∫•y Groq API key (30 gi√¢y)

```bash
# M·ªü browser
https://console.groq.com

# 1. Sign up (Google/GitHub)
# 2. V√†o "API Keys"
# 3. "Create API Key"
# 4. Copy key (gsk_...)
```

### 2. C·∫•u h√¨nh .env

```bash
# Th√™m v√†o file .env
GROQ_API_KEY=gsk_your_key_here
```

### 3. C√†i th∆∞ vi·ªán (30 gi√¢y)

```bash
pip install groq playwright
playwright install chromium
```

---

## üìñ S·ª≠ d·ª•ng

### ITViec Crawler

```bash
# Crawl 20 jobs
python src/crawler/ITViec_AI_groq.py --jobs 20

# Quick test (5 jobs)
python src/crawler/ITViec_AI_groq.py --jobs 5
```

**K·∫øt qu·∫£:**
- ‚úÖ FPT Software, VNG, Tiki, Shopee, Sendo...
- üè¢ Real companies from ITViec.com
- üíæ Auto-save to `data_raw/ITViec_AI_groq.csv`
- üîÑ Auto-merge to `data_clean/clean_data.csv`

### VietnamWorks Crawler

```bash
# Crawl 20 jobs
python src/crawler/VietnamWorks_AI_groq.py --jobs 20

# Quick test (10 jobs)
python src/crawler/VietnamWorks_AI_groq.py --jobs 10
```

**K·∫øt qu·∫£:**
- ‚úÖ FPT Software, SmartOSC, MISA, Seashore...
- üè¢ Real companies from VietnamWorks
- üíæ Auto-save to `data_raw/VietnamWorks_AI_groq.csv`
- üîÑ Auto-merge to `data_clean/clean_data.csv`

---

## üîß C√°ch ho·∫°t ƒë·ªông

### Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Playwright  ‚îÇ  1. Launch browser (stealth mode)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Get HTML    ‚îÇ  2. Navigate to website, scroll, extract HTML
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Groq API    ‚îÇ  3. Send HTML ‚Üí Llama 3.3 70B
‚îÇ  Llama 3.3   ‚îÇ     AI parses HTML semantically
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ JSON Extract ‚îÇ  4. AI returns structured JSON
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Transform   ‚îÇ  5. Transform to schema
‚îÇ  & Merge     ‚îÇ     Merge v√†o clean_data.csv
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Stealth Features

**Anti-detection:**
```python
# 1. User agent th·∫≠t
user_agent='Mozilla/5.0 (Windows NT 10.0...'

# 2. Hide automation
navigator.webdriver = undefined

# 3. Browser args
--disable-blink-features=AutomationControlled

# 4. Human-like scrolling
for i in range(3):
    scroll(i * 500)
    wait(500ms)
```

### AI Prompt Engineering

```python
prompt = f"""
Extract {num_jobs} jobs from HTML.

Look for:
- Job titles (h2, h3, class="job-title")
- Company names
- Salary ($ or VND)
- Location (Ho Chi Minh, Ha Noi, Da Nang)
- Skills (Python, Java, React...)

Return JSON:
[{
  "job_title": "...",
  "company_name": "...",
  "salary": "...",
  "level": "mid/senior/junior",
  "city": "...",
  "skills": "...",
  "description": "..."
}]

HTML: {html_snippet}
"""
```

---

## üìä Output Format

### Raw CSV (data_raw/)

```csv
job_title,company_name,salary,level,city,skills,description,crawled_at,method,source
Backend Developer,VNG Corporation,$1000-2000,mid,Ho Chi Minh,"Python,Django,PostgreSQL",Develop APIs,2026-02-04 10:30:00,Playwright + Groq Llama 3.3,ITViec
```

### Transformed (data_clean/clean_data.csv)

Auto-transform to match existing schema:
```
job_names, company_names, salaries, position_names,
kind_jobs, array_skills, locate_names, exp_skills,
domain_arr, post_dates_formatted, salary_numeric,
city, level, job_group
```

**Deduplication:**
- Drop duplicates by (`job_names`, `company_names`)
- Keep latest entry

---

## ‚öôÔ∏è C·∫•u h√¨nh n√¢ng cao

### Thay ƒë·ªïi model

```python
# src/crawler/ITViec_AI_groq.py
response = client.chat.completions.create(
    model="llama-3.3-70b-versatile",  # Fastest, free
    # model="mixtral-8x7b-32768",      # Alternative
    temperature=0.1,  # Gi·∫£m ƒë·ªÉ consistent h∆°n
    max_tokens=4000   # TƒÉng n·∫øu c·∫ßn nhi·ªÅu jobs
)
```

### Thay ƒë·ªïi HTML snippet size

```python
# TƒÉng n·∫øu extract kh√¥ng ƒë·ªß jobs
html_snippet = content[:30000]  # 30K chars

# Gi·∫£m n·∫øu API timeout
html_snippet = content[:15000]  # 15K chars
```

### Bypass CAPTCHA

```python
# Launch non-headless ƒë·ªÉ x·ª≠ l√Ω CAPTCHA th·ªß c√¥ng
browser = await p.chromium.launch(
    headless=False,  # Show browser
    slow_mo=1000     # Slow down (ms)
)
```

---

## üêõ Troubleshooting

### 1. API quota exceeded (429)

```
Error code: 429 - rate_limit_exceeded
```

**Fix:**
- ƒê·ª£i 1 ph√∫t (free tier: 30 req/min)
- Ho·∫∑c upgrade Groq plan

### 2. Browser kh√¥ng ƒë√≥ng

```
RuntimeError: Event loop is closed
```

**Fix:**
- ƒê·ª´ng Ctrl+C khi browser ƒëang ch·∫°y
- ƒê·ª£i script t·ª± ƒë·ªông ƒë√≥ng
- ƒê√£ fix trong code m·ªõi (try/except)

### 3. Extract 0 jobs

```
üìä ƒê√£ extract 0 jobs!
```

**Nguy√™n nh√¢n:**
- HTML ch∆∞a load (tƒÉng wait time)
- Website thay ƒë·ªïi layout
- AI kh√¥ng hi·ªÉu HTML format

**Fix:**
```python
# TƒÉng wait time
await page.wait_for_timeout(5000)  # 5s

# TƒÉng HTML snippet
html_snippet = content[:30000]

# Th·ª≠ model kh√°c
model="mixtral-8x7b-32768"
```

### 4. JSON parse error

```
‚ùå L·ªói parse JSON: Expecting value
```

**Fix:**
- AI tr·∫£ v·ªÅ text thay v√¨ JSON
- ƒê√£ c√≥ fallback trong code
- Check response preview trong log

### 5. Groq API error

```
‚ùå Ch∆∞a c√≥ Groq API key!
```

**Fix:**
```bash
# Check .env file
cat .env | grep GROQ

# Add key
echo "GROQ_API_KEY=gsk_your_key" >> .env

# Reload
python src/crawler/ITViec_AI_groq.py --jobs 5
```

---

## üìà Performance

### Benchmarks

| Site | Jobs | Time | Success Rate |
|------|------|------|--------------|
| ITViec | 5 | ~25s | 95% |
| ITViec | 20 | ~35s | 90% |
| VietnamWorks | 10 | ~30s | 98% |
| VietnamWorks | 20 | ~40s | 95% |

**Factors:**
- Network speed
- Website load time
- Groq API response time (~10-15s)
- HTML size (ITViec 558KB, VietnamWorks 200KB)

### Limitations

**Free tier:**
- 30 requests/minute
- ~100 requests/day (estimate)
- No rate limit on weekends (sometimes)

**Best practices:**
- Crawl 10-20 jobs per run
- ƒê·ª£i 2-3 ph√∫t gi·ªØa c√°c l·∫ßn ch·∫°y
- Schedule crawls (1-2 l·∫ßn/ng√†y)

---

## üéØ Use Cases

### 1. Daily update

```bash
# Crontab (Linux/Mac)
0 9 * * * cd /path/to/project && python src/crawler/ITViec_AI_groq.py --jobs 20

# Task Scheduler (Windows)
# 9:00 AM daily
```

### 2. Demo cho gi√°o vi√™n

```bash
# Quick demo (5 jobs, 30 seconds)
python src/crawler/ITViec_AI_groq.py --jobs 5

# Show results
python -c "import pandas as pd; df=pd.read_csv('data_raw/ITViec_AI_groq.csv'); print(df[['job_title','company_name','city']].head())"
```

### 3. Bulk crawl

```bash
# ITViec 20 jobs
python src/crawler/ITViec_AI_groq.py --jobs 20

# Wait 2 minutes
sleep 120

# VietnamWorks 20 jobs
python src/crawler/VietnamWorks_AI_groq.py --jobs 20

# Total: 40 jobs in ~3 minutes
```

---

## üîê Security

### API Key Safety

```bash
# ‚úÖ ƒê√öNG: .env file (gitignored)
GROQ_API_KEY=gsk_...

# ‚ùå SAI: Hardcode trong code
api_key = "gsk_..."  # NEVER DO THIS!

# ‚ùå SAI: Commit v√†o Git
git add .env  # NEVER!
```

### Rate Limiting

```python
import time

for page in range(1, 11):  # 10 pages
    crawl(page)
    time.sleep(120)  # Wait 2 minutes
```

---

## üìö References

- **Groq API Docs**: https://console.groq.com/docs
- **Playwright Docs**: https://playwright.dev/python/
- **Llama 3.3**: https://ai.meta.com/llama/

---

## üéì Gi·∫£i th√≠ch cho Gi√°o vi√™n

### T·∫°i sao d√πng AI thay v√¨ th∆∞ vi·ªán thu·∫ßn?

**Selenium/BeautifulSoup (Th∆∞ vi·ªán thu·∫ßn):**
```python
# ‚ùå Hard-coded, breaks khi web thay ƒë·ªïi
soup.find('div', class='job-card-v2-title')  # N·∫øu class ƒë·ªïi ‚Üí FAIL
```

**AI (Groq Llama 3.3):**
```python
# ‚úÖ AI hi·ªÉu ng·ªØ nghƒ©a, kh√¥ng c·∫ßn bi·∫øt class name
"Extract job titles from this HTML"  # AI t·ª± t√¨m d√π class ƒë·ªïi
```

### AI hi·ªÉu HTML nh∆∞ th·∫ø n√†o?

1. **Pre-training**: LLM h·ªçc t·ª´ billions web pages
2. **Pattern recognition**: H·ªçc structure c·ªßa HTML
3. **Semantic understanding**: Hi·ªÉu "job title" = h2 ho·∫∑c h3 c√≥ text job-related
4. **Zero-shot extraction**: Kh√¥ng c·∫ßn training ri√™ng cho m·ªói website

### Demo flow

```
1. Show code AI crawler (5 min)
2. Run live: python src/crawler/ITViec_AI_groq.py --jobs 5
3. Explain AI parsing (3 min)
4. Show results in dashboard (2 min)
5. Compare v·ªõi Selenium (brittle vs flexible)
```

---

## ‚úÖ Checklist

### Setup
- [ ] Groq API key l·∫•y xong
- [ ] ƒê√£ add v√†o .env
- [ ] `pip install groq playwright`
- [ ] `playwright install chromium`

### Test
- [ ] ITViec crawler: `--jobs 5`
- [ ] VietnamWorks crawler: `--jobs 10`
- [ ] Data saved to data_raw/
- [ ] Merged to data_clean/clean_data.csv

### Demo
- [ ] ƒê·ªçc AI_CRAWLING_EXPLANATION.md
- [ ] ƒê·ªçc QUICK_DEMO_GV.md
- [ ] Practice demo 1 l·∫ßn
- [ ] Prepare for Q&A

---

Made with ü§ñ by AI + ‚ù§Ô∏è by Human
